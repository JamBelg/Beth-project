{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Flatten, Dense, Input, Dropout, Conv1D, BatchNormalization, MaxPooling1D, Flatten, LSTM, Bidirectional, Embedding, Concatenate, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adamax\n",
    "\n",
    "import ast\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../../Data/labelled_training_data.csv')\n",
    "val_data = pd.read_csv('../../../Data/labelled_validation_data.csv')\n",
    "test_data = pd.read_csv('../../../Data/labelled_testing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"processId\"] = train_data[\"processId\"].map(lambda x: 0 if x in [0, 1, 2] else 1)  # Map to OS/not OS\n",
    "train_data[\"parentProcessId\"] = train_data[\"parentProcessId\"].map(lambda x: 0 if x in [0, 1, 2] else 1)  # Map to OS/not OS\n",
    "train_data[\"userId\"] = train_data[\"userId\"].map(lambda x: 0 if x < 1000 else 1)  # Map to OS/not OS\n",
    "train_data[\"mountNamespace\"] = train_data[\"mountNamespace\"].map(lambda x: 0 if x == 4026531840 else 1)  # Map to mount access to mnt/ (all non-OS users) /elsewhere\n",
    "train_data[\"eventId\"] = train_data[\"eventId\"]  # Keep eventId values (requires knowing max value)\n",
    "train_data[\"returnValue\"] = train_data[\"returnValue\"].map(lambda x: 0 if x == 0 else (1 if x > 0 else 2))\n",
    "\n",
    "\n",
    "val_data[\"processId\"] = val_data[\"processId\"].map(lambda x: 0 if x in [0, 1, 2] else 1)  # Map to OS/not OS\n",
    "val_data[\"parentProcessId\"] = val_data[\"parentProcessId\"].map(lambda x: 0 if x in [0, 1, 2] else 1)  # Map to OS/not OS\n",
    "val_data[\"userId\"] = val_data[\"userId\"].map(lambda x: 0 if x < 1000 else 1)  # Map to OS/not OS\n",
    "val_data[\"mountNamespace\"] = val_data[\"mountNamespace\"].map(lambda x: 0 if x == 4026531840 else 1)  # Map to mount access to mnt/ (all non-OS users) /elsewhere\n",
    "val_data[\"eventId\"] = val_data[\"eventId\"]  # Keep eventId values (requires knowing max value)\n",
    "val_data[\"returnValue\"] = val_data[\"returnValue\"].map(lambda x: 0 if x == 0 else (1 if x > 0 else 2)) \n",
    "\n",
    "\n",
    "test_data[\"processId\"] = test_data[\"processId\"].map(lambda x: 0 if x in [0, 1, 2] else 1)  # Map to OS/not OS\n",
    "test_data[\"parentProcessId\"] = test_data[\"parentProcessId\"].map(lambda x: 0 if x in [0, 1, 2] else 1)  # Map to OS/not OS\n",
    "test_data[\"userId\"] = test_data[\"userId\"].map(lambda x: 0 if x < 1000 else 1)  # Map to OS/not OS\n",
    "test_data[\"mountNamespace\"] = test_data[\"mountNamespace\"].map(lambda x: 0 if x == 4026531840 else 1)  # Map to mount access to mnt/ (all non-OS users) /elsewhere\n",
    "test_data[\"eventId\"] = test_data[\"eventId\"]  # Keep eventId values (requires knowing max value)\n",
    "test_data[\"returnValue\"] = test_data[\"returnValue\"].map(lambda x: 0 if x == 0 else (1 if x > 0 else 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>processId</th>\n",
       "      <th>threadId</th>\n",
       "      <th>parentProcessId</th>\n",
       "      <th>userId</th>\n",
       "      <th>mountNamespace</th>\n",
       "      <th>eventId</th>\n",
       "      <th>argsNum</th>\n",
       "      <th>returnValue</th>\n",
       "      <th>sus</th>\n",
       "      <th>evil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.000000</td>\n",
       "      <td>763144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1844.582673</td>\n",
       "      <td>0.978617</td>\n",
       "      <td>6820.265241</td>\n",
       "      <td>0.895755</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.256371</td>\n",
       "      <td>288.158953</td>\n",
       "      <td>2.672082</td>\n",
       "      <td>0.340016</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1136.638249</td>\n",
       "      <td>0.144656</td>\n",
       "      <td>1937.068333</td>\n",
       "      <td>0.305578</td>\n",
       "      <td>0.036103</td>\n",
       "      <td>0.436629</td>\n",
       "      <td>385.117778</td>\n",
       "      <td>1.340906</td>\n",
       "      <td>0.533623</td>\n",
       "      <td>0.040744</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>132.560721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>903.250802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7313.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1829.203642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2761.380825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7415.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3954.587643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8619.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp      processId       threadId  parentProcessId  \\\n",
       "count  763144.000000  763144.000000  763144.000000    763144.000000   \n",
       "mean     1844.582673       0.978617    6820.265241         0.895755   \n",
       "std      1136.638249       0.144656    1937.068333         0.305578   \n",
       "min       132.560721       0.000000       1.000000         0.000000   \n",
       "25%       903.250802       1.000000    7313.000000         1.000000   \n",
       "50%      1829.203642       1.000000    7365.000000         1.000000   \n",
       "75%      2761.380825       1.000000    7415.000000         1.000000   \n",
       "max      3954.587643       1.000000    8619.000000         1.000000   \n",
       "\n",
       "              userId  mountNamespace        eventId        argsNum  \\\n",
       "count  763144.000000   763144.000000  763144.000000  763144.000000   \n",
       "mean        0.001305        0.256371     288.158953       2.672082   \n",
       "std         0.036103        0.436629     385.117778       1.340906   \n",
       "min         0.000000        0.000000       3.000000       0.000000   \n",
       "25%         0.000000        0.000000       3.000000       1.000000   \n",
       "50%         0.000000        0.000000      62.000000       3.000000   \n",
       "75%         0.000000        1.000000     257.000000       4.000000   \n",
       "max         1.000000        1.000000    1010.000000       5.000000   \n",
       "\n",
       "         returnValue            sus      evil  \n",
       "count  763144.000000  763144.000000  763144.0  \n",
       "mean        0.340016       0.001663       0.0  \n",
       "std         0.533623       0.040744       0.0  \n",
       "min         0.000000       0.000000       0.0  \n",
       "25%         0.000000       0.000000       0.0  \n",
       "50%         0.000000       0.000000       0.0  \n",
       "75%         1.000000       0.000000       0.0  \n",
       "max         2.000000       1.000000       0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp          float64\n",
       "processId            int64\n",
       "threadId             int64\n",
       "parentProcessId      int64\n",
       "userId               int64\n",
       "mountNamespace       int64\n",
       "processName         object\n",
       "hostName            object\n",
       "eventId              int64\n",
       "eventName           object\n",
       "stackAddresses      object\n",
       "argsNum              int64\n",
       "returnValue          int64\n",
       "args                object\n",
       "sus                  int64\n",
       "evil                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Stackaddress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112474"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_addresses_df = pd.concat([train_data['stackAddresses'], val_data['stackAddresses'], test_data['stackAddresses']], axis=0)\n",
    "len(stack_addresses_df.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert String to List**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140662171848350, 11649800180280676]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert string to list\n",
    "train_data.stackAddresses = train_data.stackAddresses.apply(ast.literal_eval)\n",
    "val_data.stackAddresses = val_data.stackAddresses.apply(ast.literal_eval)\n",
    "test_data.stackAddresses = test_data.stackAddresses.apply(ast.literal_eval)\n",
    "train_data.stackAddresses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset - Max length of stack addresses: 20\n",
      "Validation dataset - Max length of stack addresses: 20\n",
      "Testing dataset - Max length of stack addresses: 20\n"
     ]
    }
   ],
   "source": [
    "train_data['stack_address_len']=train_data.stackAddresses.apply(len)\n",
    "val_data['stack_address_len']=val_data.stackAddresses.apply(len)\n",
    "test_data['stack_address_len']=test_data.stackAddresses.apply(len)\n",
    "print(f\"Training dataset - Max length of stack addresses: {max(train_data['stack_address_len'])}\")\n",
    "print(f\"Validation dataset - Max length of stack addresses: {max(val_data['stack_address_len'])}\")\n",
    "print(f\"Testing dataset - Max length of stack addresses: {max(test_data['stack_address_len'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stack_address_len\n",
       "0     521115\n",
       "2     109594\n",
       "1      65545\n",
       "3      59301\n",
       "4       2445\n",
       "20      1406\n",
       "14      1073\n",
       "15       932\n",
       "6        354\n",
       "8        347\n",
       "17       276\n",
       "10       206\n",
       "11       190\n",
       "9        143\n",
       "5         92\n",
       "16        90\n",
       "12        27\n",
       "7          8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['stack_address_len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max(train_data['stack_address_len'])):\n",
    "    train_data[f\"stack_{i+1}\"]=\"\"\n",
    "    val_data[f\"stack_{i+1}\"]=\"\"\n",
    "    test_data[f\"stack_{i+1}\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_data.iterrows():\n",
    "    list_stack = [float(elem) for elem in row['stackAddresses']]\n",
    "    for i, elem in enumerate(list_stack):\n",
    "        train_data.at[index, f'stack_{i+1}'] = elem\n",
    "\n",
    "for index, row in val_data.iterrows():\n",
    "    list_stack = [float(elem) for elem in row['stackAddresses']]\n",
    "    for i, elem in enumerate(list_stack):\n",
    "        val_data.at[index, f'stack_{i+1}'] = elem\n",
    "\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    list_stack = [float(elem) for elem in row['stackAddresses']]\n",
    "    for i, elem in enumerate(list_stack):\n",
    "        test_data.at[index, f'stack_{i+1}'] = elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                                                  1809.495787\n",
       "processId                                                            1\n",
       "threadId                                                          7337\n",
       "parentProcessId                                                      0\n",
       "userId                                                               0\n",
       "mountNamespace                                                       1\n",
       "processName                                                      close\n",
       "hostName                                               ip-10-100-1-120\n",
       "eventId                                                            157\n",
       "eventName                                                        prctl\n",
       "stackAddresses                    [140662171848350, 11649800180280676]\n",
       "argsNum                                                              5\n",
       "returnValue                                                          0\n",
       "args                 [{'name': 'option', 'type': 'int', 'value': 'P...\n",
       "sus                                                                  1\n",
       "evil                                                                 0\n",
       "stack_address_len                                                    2\n",
       "stack_1                                              140662171848350.0\n",
       "stack_2                                            11649800180280676.0\n",
       "stack_3                                                               \n",
       "stack_4                                                               \n",
       "stack_5                                                               \n",
       "stack_6                                                               \n",
       "stack_7                                                               \n",
       "stack_8                                                               \n",
       "stack_9                                                               \n",
       "stack_10                                                              \n",
       "stack_11                                                              \n",
       "stack_12                                                              \n",
       "stack_13                                                              \n",
       "stack_14                                                              \n",
       "stack_15                                                              \n",
       "stack_16                                                              \n",
       "stack_17                                                              \n",
       "stack_18                                                              \n",
       "stack_19                                                              \n",
       "stack_20                                                              \n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Args**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "argsNum\n",
       "4    359113\n",
       "1    230609\n",
       "2    149273\n",
       "3     20062\n",
       "5      2678\n",
       "0      1409\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['argsNum'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214720"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['args'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'name': 'pathname', 'type': 'const char*', 'value': '/etc/ld.so.cache'}, {'name': 'flags', 'type': 'int', 'value': 'O_RDONLY|O_LARGEFILE'}, {'name': 'dev', 'type': 'dev_t', 'value': 211812353}, {'name': 'inode', 'type': 'unsigned long', 'value': 62841}]\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['args'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split args**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the string column into list of dictionaries and create new columns\n",
    "def split_and_expand(row):\n",
    "    if pd.isna(row):\n",
    "        return pd.Series([None] * 15)\n",
    "\n",
    "    dicts = ast.literal_eval(row)\n",
    "    result = {'name_{}'.format(i+1): None for i in range(5)}\n",
    "    result.update({'type_{}'.format(i+1): None for i in range(5)})\n",
    "    result.update({'value_{}'.format(i+1): None for i in range(5)})\n",
    "\n",
    "    for i, d in enumerate(dicts):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        result['name_{}'.format(i+1)] = d.get('name')\n",
    "        result['type_{}'.format(i+1)] = d.get('type')\n",
    "        result['value_{}'.format(i+1)] = d.get('value')\n",
    "\n",
    "    return pd.Series(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_split = train_data['args'].apply(split_and_expand)\n",
    "train_data = pd.concat([train_data, args_split], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_split = val_data['args'].apply(split_and_expand)\n",
    "val_data = pd.concat([val_data, args_split], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_split = test_data['args'].apply(split_and_expand)\n",
    "test_data = pd.concat([test_data, args_split], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = train_data.sample(frac=0.4, ignore_index=True)\n",
    "\n",
    "X_num_train = train_data[['processId', 'threadId', 'parentProcessId', 'userId', 'mountNamespace', 'eventId', 'argsNum', 'returnValue', 'stack_address_len']]\n",
    "X_cat_train = train_data[['processName', 'hostName', 'eventName',\n",
    "                     'stack_1', 'stack_2', 'stack_3', 'stack_4',\n",
    "                     'stack_5', 'stack_6', 'stack_7', 'stack_8', 'stack_9', \n",
    "                     'stack_10','stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "                     'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20',\n",
    "                     'name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "                     'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "                     'value_1', 'value_2', 'value_3', 'value_4', 'value_5']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_val = val_data[['processId', 'threadId', 'parentProcessId', 'userId', 'mountNamespace', 'eventId', 'argsNum', 'returnValue', 'stack_address_len']]\n",
    "X_cat_val = val_data[['processName', 'hostName', 'eventName',\n",
    "                     'stack_1', 'stack_2', 'stack_3', 'stack_4',\n",
    "                     'stack_5', 'stack_6', 'stack_7', 'stack_8', 'stack_9', \n",
    "                     'stack_10','stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "                     'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20',\n",
    "                     'name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "                     'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "                     'value_1', 'value_2', 'value_3', 'value_4', 'value_5']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_test = test_data[['processId', 'threadId', 'parentProcessId', 'userId', 'mountNamespace', 'eventId', 'argsNum', 'returnValue', 'stack_address_len']]\n",
    "X_cat_test = test_data[['processName', 'hostName', 'eventName',\n",
    "                     'stack_1', 'stack_2', 'stack_3', 'stack_4',\n",
    "                     'stack_5', 'stack_6', 'stack_7', 'stack_8', 'stack_9', \n",
    "                     'stack_10','stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "                     'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20',\n",
    "                     'name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "                     'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "                     'value_1', 'value_2', 'value_3', 'value_4', 'value_5']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical features encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', \n",
    "                                 unknown_value=-1, dtype=float)\n",
    "\n",
    "# Encode Stack adresses\n",
    "stackaddresses_train_enc = stack_ordinal_encoder.fit_transform(X_cat_train[['stack_1', 'stack_2', 'stack_3', 'stack_4', 'stack_5',\n",
    "                                                                      'stack_6', 'stack_7', 'stack_8', 'stack_9', 'stack_10',\n",
    "                                                                      'stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "                                                                      'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_train[['stack_1', 'stack_2', 'stack_3', 'stack_4', 'stack_5',\n",
    "             'stack_6', 'stack_7', 'stack_8', 'stack_9', 'stack_10',\n",
    "             'stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "             'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20']] = stackaddresses_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackaddresses_val_enc = stack_ordinal_encoder.transform(X_cat_val[['stack_1', 'stack_2', 'stack_3', 'stack_4', 'stack_5',\n",
    "                                                        'stack_6', 'stack_7', 'stack_8', 'stack_9', 'stack_10',\n",
    "                                                        'stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "                                                        'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackaddresses_val_enc = np.where(stackaddresses_val_enc==-1, np.max(stackaddresses_train_enc)+1, stackaddresses_val_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_val[['stack_1', 'stack_2', 'stack_3', 'stack_4', 'stack_5',\n",
    "           'stack_6', 'stack_7', 'stack_8', 'stack_9', 'stack_10',\n",
    "           'stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "           'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20']]= stackaddresses_val_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackaddresses_test_enc = stack_ordinal_encoder.transform(X_cat_test[['stack_1', 'stack_2', 'stack_3', 'stack_4', 'stack_5',\n",
    "                                                        'stack_6', 'stack_7', 'stack_8', 'stack_9', 'stack_10',\n",
    "                                                        'stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "                                                        'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20']])\n",
    "\n",
    "stackaddresses_test_enc = np.where(stackaddresses_test_enc==-1, np.max(stackaddresses_train_enc)+1, stackaddresses_test_enc)\n",
    "\n",
    "X_cat_test[['stack_1', 'stack_2', 'stack_3', 'stack_4', 'stack_5',\n",
    "           'stack_6', 'stack_7', 'stack_8', 'stack_9', 'stack_10',\n",
    "           'stack_11', 'stack_12', 'stack_13', 'stack_14', 'stack_15',\n",
    "           'stack_16','stack_17', 'stack_18', 'stack_19', 'stack_20']]= stackaddresses_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Stack adresses\n",
    "args_ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, dtype=float)\n",
    "args_train_enc = args_ordinal_encoder.fit_transform(X_cat_train[['name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "                                                            'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "                                                            'value_1', 'value_2', 'value_3', 'value_4', 'value_5']])\n",
    "X_cat_train[['name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "             'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "             'value_1', 'value_2', 'value_3', 'value_4', 'value_5']] = args_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_val_enc = args_ordinal_encoder.transform(X_cat_val[['name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "                                                    'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "                                                    'value_1', 'value_2', 'value_3', 'value_4', 'value_5']])\n",
    "\n",
    "args_val_enc = np.where(args_val_enc==-1, np.max(args_train_enc)+1, args_val_enc)\n",
    "\n",
    "X_cat_val[['name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "           'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "           'value_1', 'value_2', 'value_3', 'value_4', 'value_5']] = args_val_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_test_enc = args_ordinal_encoder.transform(X_cat_test[['name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "                                                      'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "                                                      'value_1', 'value_2', 'value_3', 'value_4', 'value_5']])\n",
    "\n",
    "args_test_enc = np.where(args_test_enc==-1, np.max(args_train_enc)+1, args_test_enc)\n",
    "\n",
    "X_cat_test[['name_1', 'name_2', 'name_3', 'name_4', 'name_5',\n",
    "           'type_1', 'type_2', 'type_3', 'type_4', 'type_5',\n",
    "           'value_1', 'value_2', 'value_3', 'value_4', 'value_5']] = args_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProcessName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, dtype=float)\n",
    "X_cat_train['processName'] = proc_ordinal_encoder.fit_transform(X_cat_train[['processName']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "processName_val_enc = proc_ordinal_encoder.transform(X_cat_val[['processName']])\n",
    "processName_val_enc = np.where(processName_val_enc==-1, np.max(X_cat_train['processName'])+1, processName_val_enc)\n",
    "X_cat_val['processName'] = processName_val_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "processName_test_enc = proc_ordinal_encoder.transform(X_cat_test[['processName']])\n",
    "processName_test_enc = np.where(processName_test_enc==-1, np.max(X_cat_train['processName'])+1, processName_test_enc)\n",
    "X_cat_test['processName'] = processName_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HostName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, dtype=float)\n",
    "X_cat_train['hostName'] = host_ordinal_encoder.fit_transform(X_cat_train[['hostName']])\n",
    "\n",
    "host_val_enc = host_ordinal_encoder.transform(X_cat_val[['hostName']])\n",
    "host_val_enc = np.where(host_val_enc==-1, np.max(X_cat_train['hostName'])+1, host_val_enc)\n",
    "X_cat_val['hostName'] = host_val_enc\n",
    "\n",
    "host_test_enc = host_ordinal_encoder.transform(X_cat_test[['hostName']])\n",
    "host_test_enc = np.where(host_test_enc==-1, np.max(X_cat_train['hostName'])+1, host_test_enc)\n",
    "X_cat_test['hostName'] = host_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EventName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, dtype=float)\n",
    "X_cat_train['eventName'] = event_ordinal_encoder.fit_transform(X_cat_train[['eventName']])\n",
    "\n",
    "event_val_enc = event_ordinal_encoder.transform(X_cat_val[['eventName']])\n",
    "event_val_enc = np.where(event_val_enc==-1, np.max(X_cat_train['eventName'])+1, event_val_enc)\n",
    "X_cat_val['eventName'] = event_val_enc\n",
    "\n",
    "event_test_enc = event_ordinal_encoder.transform(X_cat_test[['eventName']])\n",
    "event_test_enc = np.where(event_test_enc==-1, np.max(X_cat_train['eventName'])+1, event_test_enc)\n",
    "X_cat_test['eventName'] = event_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_num_train, X_cat_train], axis=1)\n",
    "y_train = train_data['sus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.concat([X_num_val, X_cat_val], axis=1)\n",
    "y_val = val_data['sus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_num_test, X_cat_test], axis=1)\n",
    "y_test = test_data['sus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler1 = StandardScaler()\n",
    "X_train_scaled = scaler1.fit_transform(X_train)\n",
    "X_val_scaled = scaler1.transform(X_val)\n",
    "X_test_scaled = scaler1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8449, 26665, 37, 33, 9)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_unique_stack = (np.max(stackaddresses_train_enc)+2).astype('int')\n",
    "n_unique_args = (np.max(args_train_enc)+2).astype('int')\n",
    "n_unique_proc = (np.max(X_cat_train['processName'])+2).astype('int')\n",
    "n_unique_event = (np.max(X_cat_train['eventName'])+2).astype('int')\n",
    "n_unique_host = (np.max(X_cat_train['hostName'])+2).astype('int')\n",
    "\n",
    "n_unique_stack,n_unique_args,n_unique_proc,n_unique_event,n_unique_host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Torch model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        assert self.head_dim * num_heads == embed_dim, \"Embedding dimension must be divisible by number of heads\"\n",
    "        \n",
    "        self.query_fc = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key_fc = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value_fc = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc_out = nn.Linear(embed_dim, embed_dim)\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        query = self.query_fc(query)\n",
    "        key = self.key_fc(key)\n",
    "        value = self.value_fc(value)\n",
    "        \n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        scores = torch.matmul(query, key.permute(0, 1, 3, 2)) / np.sqrt(self.head_dim)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        \n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attention_weights, value)\n",
    "        \n",
    "        context = context.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.num_heads * self.head_dim)\n",
    "        \n",
    "        return self.fc_out(context)\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, max_len, embed_dim):\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-np.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_1_vocab_size, input_2_vocab_size, \n",
    "                 input_3_vocab_size, input_4_vocab_size, \n",
    "                 input_5_vocab_size, input_3_input_size, \n",
    "                 embed_dim, num_heads):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding_1 = nn.Embedding(input_1_vocab_size, embed_dim)\n",
    "        self.embedding_2 = nn.Embedding(input_2_vocab_size, embed_dim)\n",
    "        self.embedding_3 = nn.Embedding(input_3_vocab_size, embed_dim)\n",
    "        self.embedding_4 = nn.Embedding(input_4_vocab_size, embed_dim)\n",
    "        self.embedding_5 = nn.Embedding(input_5_vocab_size, embed_dim)\n",
    "        \n",
    "        self.positional_encoder = PositionalEncoder(max_len=max(input_1_vocab_size, input_2_vocab_size,\n",
    "                                                                input_3_vocab_size, input_4_vocab_size,\n",
    "                                                                input_5_vocab_size), embed_dim=embed_dim)\n",
    "        \n",
    "        self.multihead_attention = MultiHeadAttention(embed_dim, num_heads)\n",
    "        \n",
    "        self.fc = nn.Linear(embed_dim, 2)  # Output classes are 2 for binary classification\n",
    "        \n",
    "    def forward(self, input_cat_1, input_cat_2, input_cat_3, input_cat_4, input_cat_5, input_num):\n",
    "        embedded_input_1 = self.embedding_1(input_cat_1)\n",
    "        embedded_input_2 = self.embedding_2(input_cat_2)\n",
    "        embedded_input_3 = self.embedding_3(input_cat_3)\n",
    "        embedded_input_4 = self.embedding_4(input_cat_4)\n",
    "        embedded_input_5 = self.embedding_5(input_cat_5)\n",
    "        \n",
    "        embedded_inputs = embedded_input_1 + embedded_input_2 + embedded_input_3 + embedded_input_4 + embedded_input_5\n",
    "        \n",
    "        embedded_inputs = self.positional_encoder(embedded_inputs)\n",
    "        \n",
    "        attention_output = self.multihead_attention(embedded_inputs, embedded_inputs, embedded_inputs)\n",
    "        \n",
    "        output = self.fc(attention_output.mean(dim=1))  # Pooling operation\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Example usage:\n",
    "input_1_vocab_size = n_unique_stack\n",
    "input_2_vocab_size = n_unique_args\n",
    "input_3_vocab_size = n_unique_proc\n",
    "input_4_vocab_size = n_unique_event\n",
    "input_5_vocab_size = n_unique_host\n",
    "input_3_input_size = 9\n",
    "embed_dim = 32\n",
    "num_heads = 4\n",
    "\n",
    "model = TransformerClassifier(input_1_vocab_size, input_2_vocab_size, input_3_input_size, embed_dim, num_heads)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,081,472</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,413,120</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_9         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encodin… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncodin…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,054,848</span> │ positional_encod… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ positional_encod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_encod… │\n",
       "│                     │                   │            │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">137</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,081,472\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m3,413,120\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m4,736\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m4,224\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_9         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m1,152\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ embedding_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encodin… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mPositionalEncodin…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,054,848\u001b[0m │ positional_encod… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ positional_encod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ positional_encod… │\n",
       "│                     │                   │            │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m16,512\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m137\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m17,664\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,602,561</span> (21.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,602,561\u001b[0m (21.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,602,561</span> (21.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,602,561\u001b[0m (21.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Concatenate, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_transformer_model(input_cat1_shape, input_cat2_shape, input_cat3_shape, input_cat4_shape, input_cat5_shape, input_num_shape,\n",
    "                             input_cat1_vocab, input_cat2_vocab, input_cat3_vocab, input_cat4_vocab, input_cat5_vocab):\n",
    "    # Define categorical input layers\n",
    "    input_cat1 = Input(shape=(input_cat1_shape,))\n",
    "    input_cat2 = Input(shape=(input_cat2_shape,))\n",
    "    input_cat3 = Input(shape=(input_cat3_shape,))\n",
    "    input_cat4 = Input(shape=(input_cat4_shape,))\n",
    "    input_cat5 = Input(shape=(input_cat5_shape,))\n",
    "\n",
    "    # Define embedding layers\n",
    "    embedding_size = 128\n",
    "    embed_cat1 = Embedding(input_dim=input_cat1_vocab, output_dim=embedding_size)(input_cat1)\n",
    "    embed_cat2 = Embedding(input_dim=input_cat2_vocab, output_dim=embedding_size)(input_cat2)\n",
    "    embed_cat3 = Embedding(input_dim=input_cat3_vocab, output_dim=embedding_size)(input_cat3)\n",
    "    embed_cat4 = Embedding(input_dim=input_cat4_vocab, output_dim=embedding_size)(input_cat4)\n",
    "    embed_cat5 = Embedding(input_dim=input_cat5_vocab, output_dim=embedding_size)(input_cat5)\n",
    "\n",
    "    # Concatenate embedding layers\n",
    "    concat_embeds = Concatenate(axis=1)([embed_cat1, embed_cat2, embed_cat3, embed_cat4, embed_cat5])\n",
    "\n",
    "    # Positional encoding\n",
    "    pos_enc = PositionalEncoding(input_cat1_shape + input_cat2_shape + input_cat3_shape + \n",
    "                                 input_cat4_shape + input_cat5_shape, embedding_size)(concat_embeds)\n",
    "\n",
    "    # Transformer Encoder Block\n",
    "    encoder_output = transformer_encoder_block(pos_enc, num_heads=8, ff_dim=128)\n",
    "\n",
    "    # Global average pooling\n",
    "    encoder_output = GlobalAveragePooling1D()(encoder_output)\n",
    "\n",
    "    # Concatenate with numerical input\n",
    "    input_num = Input(shape=(input_num_shape,))\n",
    "    all_features = Concatenate()([encoder_output, input_num])\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Dense(128, activation='relu')(all_features)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Define model\n",
    "    model = Model(inputs=[input_cat1, input_cat2, input_cat3, input_cat4, input_cat5, input_num], outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "def transformer_encoder_block(inputs, num_heads, ff_dim, dropout_rate=0.1, embedding_size=256):\n",
    "    # Multi-head self-attention\n",
    "    attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_size)(inputs, inputs)\n",
    "    attention = Dropout(dropout_rate)(attention)\n",
    "    attention = LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # Feed-forward layer\n",
    "    outputs = Dense(ff_dim, activation='relu')(attention)\n",
    "    outputs = Dropout(dropout_rate)(outputs)\n",
    "    outputs = LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.positional_encoding = self.positional_encoding(sequence_length, output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.positional_encoding\n",
    "\n",
    "    def positional_encoding(self, sequence_length, output_dim):\n",
    "        encoded_vec = np.array([pos / np.power(10000, 2 * i / output_dim) for pos in range(sequence_length) for i in range(output_dim)])\n",
    "        encoded_vec[::2] = np.sin(encoded_vec[::2])\n",
    "        encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n",
    "        return tf.constant(encoded_vec.reshape([sequence_length, output_dim]), dtype=tf.float32)\n",
    "\n",
    "# Example usage\n",
    "input_cat1_shape = 20\n",
    "input_cat2_shape = 15\n",
    "input_cat3_shape = 1\n",
    "input_cat4_shape = 1\n",
    "input_cat5_shape = 1\n",
    "input_num_shape = 9\n",
    "\n",
    "model = create_transformer_model(input_cat1_shape, input_cat2_shape, input_cat3_shape, input_cat4_shape, input_cat5_shape, input_num_shape,\n",
    "                                 n_unique_stack, n_unique_args, n_unique_proc, n_unique_event, n_unique_host)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m999s\u001b[0m 669ms/step - accuracy: 0.9907 - loss: 2.3579 - val_accuracy: 0.9958 - val_loss: 0.0070\n",
      "Epoch 2/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1006s\u001b[0m 675ms/step - accuracy: 0.9972 - loss: 0.0347 - val_accuracy: 0.9958 - val_loss: 0.0065\n",
      "Epoch 3/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m996s\u001b[0m 668ms/step - accuracy: 0.9983 - loss: 0.0101 - val_accuracy: 0.9958 - val_loss: 0.0067\n",
      "Epoch 4/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m997s\u001b[0m 668ms/step - accuracy: 0.9983 - loss: 0.0075 - val_accuracy: 0.9958 - val_loss: 0.0051\n",
      "Epoch 5/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 664ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9958 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m992s\u001b[0m 665ms/step - accuracy: 0.9985 - loss: 0.0023 - val_accuracy: 0.9998 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m992s\u001b[0m 666ms/step - accuracy: 0.9998 - loss: 7.9428e-04 - val_accuracy: 0.9998 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m987s\u001b[0m 662ms/step - accuracy: 0.9999 - loss: 4.4524e-04 - val_accuracy: 0.9998 - val_loss: 0.0111\n",
      "Epoch 9/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m994s\u001b[0m 666ms/step - accuracy: 0.9999 - loss: 2.7276e-04 - val_accuracy: 0.9998 - val_loss: 0.0149\n",
      "Epoch 10/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 667ms/step - accuracy: 0.9999 - loss: 3.5214e-04 - val_accuracy: 0.9998 - val_loss: 0.0235\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([X_cat_train.iloc[:,3:23],\n",
    "                     X_cat_train.iloc[:,23:44],\n",
    "                     X_cat_train.iloc[:,0],\n",
    "                     X_cat_train.iloc[:,2],\n",
    "                     X_cat_train.iloc[:,1],\n",
    "                     X_num_train],  # Input data\n",
    "                    y_train,  # Labels\n",
    "                    epochs=10,  # Number of epochs\n",
    "                    batch_size=512,  # Batch size\n",
    "                    validation_data=([X_cat_val.iloc[:,3:23],\n",
    "                                      X_cat_val.iloc[:,23:44],\n",
    "                                      X_cat_val.iloc[:,0],\n",
    "                                      X_cat_val.iloc[:,2],\n",
    "                                      X_cat_val.iloc[:,1],X_num_val],\n",
    "                                     y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pred = model([X_cat_test.iloc[:,3:23],\n",
    "              X_cat_test.iloc[:,23:44],\n",
    "              X_cat_test.iloc[:,0],\n",
    "              X_cat_test.iloc[:,2],\n",
    "              X_cat_test.iloc[:,1],\n",
    "              X_num_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_threshold = np.where(pred>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TransformerEncoder' from 'transformers' (/Users/jamelbelgacem/Documents/Python/Deep learning/Beth cybersecurity/virtual_env/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerEncoder, TransformerEncoderLayer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyTransformer\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TransformerEncoder' from 'transformers' (/Users/jamelbelgacem/Documents/Python/Deep learning/Beth cybersecurity/virtual_env/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import TransformerEncoder, TransformerEncoderLayer\n",
    "from torchvision import transforms\n",
    "\n",
    "class MyTransformer(nn.Module):\n",
    "  def __init__(self, vocab_size_stack, vocab_size_args, vocab_size_proc, vocab_size_event, vocab_size_host, \n",
    "               embedding_dim, num_heads, ff_dim, num_encoder_blocks, num_features):\n",
    "    super().__init__()\n",
    "\n",
    "    # Embedding layers for categorical features\n",
    "    self.embedding_stack = nn.Embedding(vocab_size_stack, embedding_dim)\n",
    "    self.embedding_args = nn.Embedding(vocab_size_args, embedding_dim)\n",
    "    self.embedding_proc = nn.Embedding(vocab_size_proc, embedding_dim)\n",
    "    self.embedding_event = nn.Embedding(vocab_size_event, embedding_dim)\n",
    "    self.embedding_host = nn.Embedding(vocab_size_host, embedding_dim)\n",
    "\n",
    "    # Linear layer for numerical feature\n",
    "    self.linear_num = nn.Linear(num_features, embedding_dim)\n",
    "\n",
    "    # Positional encoding layer using torchvision.transforms\n",
    "    self.positional_encoding = transforms.PositionalEncoding(d_model=embedding_dim, max_len=...)  # Replace ... with your maximum sequence length\n",
    "\n",
    "    # Transformer encoder block\n",
    "    self.transformer_encoder = nn.TransformerEncoder(TransformerEncoderLayer(embedding_dim, num_heads, ff_dim), num_layers=num_encoder_blocks)\n",
    "\n",
    "    # Output layer\n",
    "    self.output_layer = nn.Linear(embedding_dim, 1)  # Assuming binary classification\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
